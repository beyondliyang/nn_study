{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(\"./data/mnist.pkl.gz\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuple_data, valid_tuple_data, test_tuple_data = pickle.load(f, encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_tuple_data[0]\n",
    "train_label = train_tuple_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_label = []\n",
    "for label in train_label:\n",
    "    one_hot_label = np.zeros([10])\n",
    "    one_hot_label[label] = 1\n",
    "    one_hot_train_label.append(one_hot_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = valid_tuple_data[0]\n",
    "valid_label = valid_tuple_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_tuple_data[0]\n",
    "test_label = test_tuple_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络\n",
    "net = [784, 40, 10]\n",
    "num_layers = len(net)\n",
    "weights = [np.random.randn(i, j) for i, j in zip(net[:-1], net[1:])]\n",
    "bias = [np.random.randn(i) for i in net[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_derivative(output_activations, y):\n",
    "    return (output_activations - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(batch_data):\n",
    "    a = batch_data\n",
    "    for w, b in zip(weights, bias):\n",
    "        z = np.matmul(a, w) + b\n",
    "        a = sigmoid(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(batch_data, batch_label):\n",
    "    zs = []\n",
    "    activates = [batch_data]\n",
    "    #前向传播\n",
    "    for w, b in zip(weights, bias):\n",
    "        z = np.matmul(activates[-1], w) + b\n",
    "        zs.append(z)\n",
    "        activates.append(sigmoid(z))\n",
    "    \n",
    "    #delta的值\n",
    "    delta = cost_derivative(activates[-1], batch_label) * sigmoid_derivative(zs[-1])\n",
    "    #填充位，用于放参数\n",
    "    nalba_w = [np.zeros(w.shape) for w in weights]\n",
    "    nalba_b = [np.zeros(b.shape) for b in bias]\n",
    "    nalba_b[-1] = delta\n",
    "    nalba_w[-1] =  np.matmul(activates[-2].transpose(), delta)\n",
    "    for l in range(2, len_net):\n",
    "        sp = sigmoid_derivative(zs[-l])\n",
    "        delta = np.matmul(delta, weights[-l+1].transpose()) * sp\n",
    "        nalba_b[-l] = delta\n",
    "        nalba_w[-l] = np.matmul(activates[-l-1].transpose(), delta)\n",
    "    return nalba_w, nalba_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'len_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8ec72fa310db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mbatch_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot_train_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mnalba_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnalba_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#跟新w,b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7a160a5a17c6>\u001b[0m in \u001b[0;36mback_prop\u001b[1;34m(batch_data, batch_label)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mnalba_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mnalba_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0msp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'len_net' is not defined"
     ]
    }
   ],
   "source": [
    "epoch_num = 30\n",
    "for epoch in range(epoch_num):\n",
    "    batch_size = 10\n",
    "    batch_num = len(train_data)//batch_size\n",
    "    for batch in range(batch_num):\n",
    "        begin = batch * batch_size\n",
    "        end = begin + batch_size\n",
    "        batch_data = train_data[begin:end]\n",
    "        batch_label = one_hot_train_label[begin:end]\n",
    "\n",
    "        nalba_w, nalba_b = back_prop(batch_data, batch_label)\n",
    "        #跟新w,b\n",
    "        eta = 3.0\n",
    "        weights = [w - (eta * nw / batch_size) for w, nw in zip(weights, nalba_w)]\n",
    "        bias = [b - (eta*np.sum(nb, axis=0) / batch_size) for b, nb in zip(bias, nalba_b)]\n",
    "    \n",
    "    x = forward(test_data)\n",
    "    y = np.argmax(x, axis=1)\n",
    "    correct_num = np.sum(y == test_label)\n",
    "    print(\"epoch:{0}\\tcorret:{1}/{2}\".format(epoch, correct_num, len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
